# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

WebNeuralNet is a modular CartPole reinforcement learning visualization built with Vite. The project provides an interactive HTML/JavaScript application for training a neural network agent to balance a pole using advanced Actor-Critic methods with Generalized Advantage Estimation (GAE) and Adam optimizer.

## Architecture

The project uses a modern modular structure with ES6 modules and Vite for development/bundling:

- **File Structure**: Modular with organized directories for ML, visualization, UI, and utilities
- **Build Tool**: Vite (modern dev server with HMR, fast bundling)
- **Output**: Generates optimized `dist/` directory with `index.html` + bundled JavaScript/CSS
- **Technology Stack**:
  - **Frontend**: Pure HTML5 Canvas + SVG, vanilla JavaScript (no frameworks)
  - **Build**: Vite 5.x + Terser minification
  - **Module System**: ES6 modules with proper imports/exports
  - **RL Algorithm**: Actor-Critic with GAE (Generalized Advantage Estimation, λ=0.95)
  - **Optimizer**: Adam optimizer with adaptive learning rates and momentum
  - **Network Architecture**: Multi-layer configurable (4 → [hidden layers] → 2 Actor + 1 Critic)
  - **Activation Functions**: ReLU, Tanh, ELU, Swish (user-selectable)
  - **Environment**: CartPole physics simulation in JavaScript

## Project Structure

```
WebNeuralNet/
├── index.html              # Main HTML template
├── package.json            # Node.js dependencies & scripts
├── vite.config.js          # Vite configuration
├── src/
│   ├── main.js             # Application entry point
│   ├── app/
│   │   └── rl_sandbox.js   # Main application controller (811 lines)
│   ├── ml/
│   │   ├── adam_optimizer.js           # Adaptive moment optimizer (46 lines)
│   │   ├── cartpole.js                 # Physics simulation (63 lines)
│   │   └── actor_critic_network.js     # Neural network with backprop (500 lines)
│   ├── viz/
│   │   ├── renderer.js                 # Canvas visualization (157 lines)
│   │   ├── network_visualizer.js       # SVG network graph (158 lines)
│   │   ├── training_chart.js           # Episode performance (149 lines)
│   │   ├── training_loss_chart.js      # Loss tracking (105 lines)
│   │   └── state_space_heatmap.js      # State-value visualization (105 lines)
│   ├── ui/
│   │   ├── metrics_dashboard.js        # Real-time metrics (43 lines)
│   │   └── replay_buffer.js            # Experience replay (54 lines)
│   ├── utils/
│   │   ├── constants.js                # Configuration constants (53 lines)
│   │   ├── helpers.js                  # Utility functions (27 lines)
│   │   └── toast.js                    # Notifications (48 lines)
│   └── styles/
│       ├── base.css                    # Base layout & typography (121 lines)
│       ├── components.css              # Component styles (662 lines)
│       └── animations.css              # Keyframes & transitions (60 lines)
├── dist/                   # Production build (generated by Vite)
└── node_modules/          # npm dependencies

```

## Key Components

### Application Layer (`src/app/`)
- **RLSandbox**: Main orchestrator (811 lines)
  - Manages training/testing loops
  - Handles UI events and control inputs
  - Coordinates all visualization updates
  - Manages save/load and data export

### Machine Learning (`src/ml/`)

1. **Adam Optimizer Class**: Adaptive moment estimation optimizer
   - Momentum and adaptive learning rates (β1=0.9, β2=0.999)
   - Bias correction for first and second moment estimates
   - Supports both 1D vectors and 2D matrices

2. **ActorCriticNetwork Class**: Dual-head neural network
   - **Actor Head**: Policy network (softmax output for action probabilities)
   - **Critic Head**: Value function network (predicts state value)
   - Multi-layer architecture with configurable hidden layers
   - Multiple activation functions (ReLU, Tanh, ELU, Swish)
   - GAE advantage estimation with λ parameter
   - Gradient clipping by global norm (prevents divergence)

3. **CartPole Class**: Environment physics
   - State: [x, x_dot, theta, theta_dot]
   - Action: 0 (left) or 1 (right) force
   - Reward: 1 per step until failure or max steps reached
   - Customizable physics parameters (gravity, pole length, friction, force magnitude)

4. **Renderer Class**: Canvas-based visualization
   - Real-time CartPole rendering with physics visualization
   - Color-coded pole angle (green→orange→red based on criticality)
   - Velocity vectors and warning indicators

5. **NetworkVisualizer Class**: Real-time network visualization
   - SVG network graph with dynamic layer support
   - Weight visualization (green=positive, red=negative)
   - Separate coloring for Actor (green), Critic (blue), and hidden layers
   - Node activation opacity based on values

6. **TrainingChart Class**: Episode performance tracking
   - Moving average calculation (10-episode window)
   - Grid-based rendering with Y-axis labels
   - Handles arbitrary number of episodes

7. **RLSandbox Class**: Main application logic
   - Training loop with configurable exploration (ε-greedy)
   - Testing and manual control modes
   - Real-time metric tracking and visualization
   - Learning rate and hyperparameter adjustment during training

### Configuration

Tunable hyperparameters (accessible via UI controls):
- **Learning Rate**: 0.0001 - 0.01, default 0.003 (applies to all Adam optimizers)
- **Discount Factor (γ)**: 0.90 - 1.0, default 0.99
- **Entropy Coefficient**: 0.0 - 0.1, default 0.02 (encourages exploration)
- **Hidden Layer Size**: 16 - 256, default 32
- **Network Depth**: 1-3 hidden layers (configurable architecture)
- **Activation Function**: ReLU (default), Tanh, ELU, or Swish
- **Training Speed**: 1x - 10x (multiplier for episodes per second)
- **GAE Lambda**: Fixed at λ=0.95 (controls variance-bias tradeoff)

## Development Workflow

### Setup & Running

1. **First-time setup**:
   ```bash
   npm install
   ```

2. **Development server** (with Hot Module Replacement):
   ```bash
   npm run dev
   ```
   - Opens browser automatically at `http://localhost:5173`
   - Changes to any `.js` or `.css` file update instantly (no page reload)
   - Best for iterative development

3. **Production build**:
   ```bash
   npm run build
   ```
   - Creates optimized bundle in `dist/` directory
   - Files are minified with Terser
   - Ready for deployment

4. **Preview production build locally**:
   ```bash
   npm run preview
   ```
   - Serves the production build from `dist/` for testing

### Common Development Tasks

#### Modify HTML Structure

Edit `index.html`:
- Add/remove form controls in the `<body>` section
- Update meta tags and title
- CSS imports are automatic via Vite

#### Adjust Hyperparameter Defaults

Edit `src/utils/constants.js`:
- `CFG.lr`: Learning rate (0.0001 - 0.01)
- `CFG.gamma`: Discount factor (0.90 - 1.0)
- `CFG.hidden`: Hidden layer size (16 - 256)
- `CFG.clip`: Gradient clipping threshold
- `CFG.entropy`: Entropy regularization coefficient
- `CFG.maxSteps`: Maximum episode length

#### Add a New Visualization Component

1. Create `src/viz/my_chart.js` with your component class
2. Import in `src/main.js`
3. Instantiate in `src/app/rl_sandbox.js`
4. Add corresponding CSS in `src/styles/components.css`

#### Add UI Controls

1. Add HTML elements to `index.html`
2. Add event listeners in `src/app/rl_sandbox.js` (or create new module in `src/ui/`)
3. Add corresponding CSS styling in `src/styles/components.css`

#### Import a Component

All components use ES6 modules:
```javascript
import { MyClass } from './path/to/my_class.js';
```

Each class must have:
- `export class ClassName { ... }`
- Proper imports at the top for its dependencies

### Algorithm Details

The training uses an Actor-Critic approach with Generalized Advantage Estimation:

**Forward Pass:**
- State input: [x, x_dot, theta, theta_dot]
- Actor head: Outputs softmax probabilities for 2 actions
- Critic head: Outputs scalar value estimate V(s)

**Advantage Estimation (GAE):**
- TD residuals: δ_t = r_t + γV(s_{t+1}) - V(s_t)
- GAE advantages: A_t = δ_t + (γλ)δ_{t+1} + (γλ)²δ_{t+2} + ...
- λ = 0.95 controls bias-variance tradeoff
- Advantages are normalized (zero-mean, unit-variance)

**Loss Functions:**
- Actor loss: -log(π(a|s)) × A(s,a) - H(π(s)) × entropy_coef
- Critic loss: MSE(V(s), R_t) where R_t = A_t + V(s)
- H(π) = -Σ π(a) log(π(a)) encourages exploration

**Optimization:**
- Adam optimizer with β1=0.9, β2=0.999, ε=1e-8
- Per-parameter adaptive learning rates
- Gradient clipping by global norm (prevents divergence)
- Supports dynamic learning rate adjustment during training

## Mobile Optimization Notes

The UI is optimized for mobile with:
- Flexible layout using CSS flexbox
- Safe area insets for notched devices
- Touch-friendly controls with proper spacing
- Responsive canvas scaling using device pixel ratio
- Viewport constraints to prevent zoom issues

## Performance Considerations

- **Gradient Accumulation**: Gradients accumulated across trajectory before update (no GC pressure)
- **Pre-allocated Buffers**: All matrices/vectors created once in constructor
- **Adam State**: First and second moment estimates maintained separately for stability
- **Batch Processing**: Episode trajectory processed in single update call
- **Learning Rate Decay**: Exploration epsilon decays from 0.2 → 0.05 across training
- **Responsive UI**: Network visualization and metrics update at 60 FPS
- **Configurable Speed**: Training speed (1-10x) adjusts episode execution speed

## Features

- **Multi-layer Networks**: 1-3 configurable hidden layers with sizes from 16-256 neurons
- **Multiple Activations**: Choose between ReLU, Tanh, ELU, or Swish per network
- **Manual Control Mode**: Test the CartPole manually with arrow keys or A/D
- **Real-time Metrics**:
  - Gradient norm and advantage tracking
  - Policy entropy monitoring
  - Value function estimates
  - Input importance visualization
- **Training Diagnostics**: Visible gradient norms, advantage statistics, and exploration rate

## Migration from Legacy Architecture

The project was refactored from a single-file Python generator (`generate.py`, 3,484 lines) to a modern modular Vite-based structure:

### What Changed

**Old Architecture:**
- Single `generate.py` file containing 3,484 lines
- HTML string embedded in Python variable `html_v3`
- All CSS, HTML, and JavaScript in one output file
- Manual file editing and HTML escaping required

**New Architecture:**
- Organized modular structure with 15 JavaScript/CSS files
- ES6 modules with proper imports/exports
- Vite development server with HMR
- Modern build tooling with npm and package.json

### Benefits of Modular Structure

1. **Better Navigation**: Easy to find specific components in organized directories
2. **Faster Development**: Hot Module Replacement (HMR) - changes appear instantly
3. **Reusability**: Components can be imported/used in other projects
4. **Testability**: Individual modules can be tested in isolation
5. **Maintainability**: Clear separation of concerns (ML, viz, UI, utils)
6. **Version Control**: Easier to track changes to specific components
7. **Scalability**: Easy to add new features without bloating single file
8. **Build System**: Automatic minification, tree-shaking, and optimization

## Environment Setup

### Requirements
- **Node.js**: 14.x or higher (for npm)
- **npm**: 6.x or higher

### Recommended Development Setup
- **IDE**: VS Code with ES6 module support
- **Extensions**: Live Server or Vite preview for quick testing
- **Browser**: Modern browser with ES6 module support (Chrome, Firefox, Safari, Edge)
